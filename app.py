# app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from prophet import Prophet
import os
import io
import base64
from transformers import pipeline
#import openpyxl

# CONFIGURACIÃ“N
USE_TRANSFORMERS = True  # Cambia a False si se utilizara OpenAI

# Chatbot (con Transformers)
if USE_TRANSFORMERS:
    from transformers import pipeline

    @st.cache_resource
    def cargar_chatbot_local():
        return pipeline("text2text-generation", model="google/flan-t5-base")

    chatbot = cargar_chatbot_local()
else:
    import openai
    openai.api_key = os.getenv("OPENAI_API_KEY")

# FunciÃ³n combinada: responder con predicciones y datos reales
def responder_chat(mensaje, df_pred, df_real):
    # Resumen de predicciones (si existe)
    if 'yhat' in df_pred.columns:
        resumen_pred = df_pred.groupby(['Country', 'Coffee type', 'Year'])['yhat'].sum().reset_index().head(10).to_string(index=False)
    else:
        resumen_pred = "Sin datos proyectados disponibles."

    # Resumen de datos reales
    resumen_real = df_real.groupby(['Country', 'Coffee type', 'Year'])['Consumption'].sum().reset_index().head(10).to_string(index=False)

    # Prompt unificado
    prompt = f"""
ActÃºa como un analista experto en consumo de cafÃ©. Tienes dos fuentes de datos:

1ï¸âƒ£ **HistÃ³rico de consumo real** (en nÃºmero de tazas):
{resumen_real}

2ï¸âƒ£ **Proyecciones de consumo futuro**:
{resumen_pred}

Con base en eso, responde en espaÃ±ol, de forma clara, la siguiente pregunta del usuario:
\"\"\"{mensaje}\"\"\"
"""

    if USE_TRANSFORMERS:
        salida = chatbot(prompt, max_length=512, do_sample=False)[0]["generated_text"]
        return salida.strip()
    else:
        respuesta = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Eres un analista de datos de cafÃ©."},
                {"role": "user", "content": prompt}
            ]
        )
        return respuesta.choices[0].message.content.strip()

# Carga de datos reales
@st.cache_data
def cargar_datos():
    df = pd.read_parquet("coffee_db.parquet")
    df = df.rename(columns=lambda x: x.strip())
    df_long = df.melt(id_vars=['Country', 'Coffee type'],
                      value_vars=[col for col in df.columns if "/" in col],
                      var_name='Year', value_name='Consumption')
    df_long['Year'] = df_long['Year'].str[:4].astype(int)
    df_long['Country'] = df_long['Country'].str.strip()
    df_long['Coffee type'] = df_long['Coffee type'].str.strip()
    df_long = df_long.dropna(subset=['Consumption'])
    return df_long
    
def entrenar_modelo(df, columna_fecha='Year', columna_valor='Consumption', horizonte=15):
    df_model = df.rename(columns={columna_valor: 'y'})
    df_model['ds'] = pd.to_datetime(df_model[columna_fecha], format='%Y')
    df_model = df_model[['ds', 'y']]
    model = Prophet()
    model.fit(df_model)
    future = model.make_future_dataframe(periods=horizonte, freq='YE')
    forecast = model.predict(future)
    forecast['Year'] = forecast['ds'].dt.year
    return model, forecast

def descripcion_tendencia(forecast):
    inicio, fin = forecast['yhat'].iloc[0], forecast['yhat'].iloc[-1]
    variacion = fin - inicio
    tendencia = "aumentÃ³" if variacion > 0 else "disminuyÃ³" if variacion < 0 else "se mantuvo estable"
    porcentaje = (variacion / inicio) * 100 if inicio != 0 else 0
    recomendacion = {
        "aumentÃ³": "ampliar presencia en el mercado y reforzar campaÃ±as de fidelizaciÃ³n.",
        "disminuyÃ³": "ajustar estrategias y buscar nuevos segmentos de mercado.",
        "se mantuvo estable": "conservar esfuerzos actuales e investigar oportunidades emergentes."
    }[tendencia]
    st.markdown(f"""
**ğŸ“Œ Entre {forecast['Year'].min()} y {forecast['Year'].max()}, el consumo {tendencia} de {int(inicio):,} a {int(fin):,} tazas ({porcentaje:.1f}%).**  
**ğŸ’¡ RecomendaciÃ³n de ventas:** {recomendacion}
""")

# APP
st.set_page_config(layout="wide")
st.title("â˜• AnÃ¡lisis Global y Proyecciones del Consumo de CafÃ© (en tazas)")

df_long = cargar_datos()

# Consumo global total
st.header("ğŸŒ Consumo Global Total Anual")
consumo_global = df_long.groupby('Year')['Consumption'].sum().reset_index()
model_global, forecast_global = entrenar_modelo(consumo_global, 'Year', 'Consumption', horizonte=2035 - consumo_global['Year'].max())

fig1 = plt.figure(figsize=(10,4))
plt.plot(forecast_global['Year'], forecast_global['yhat'], label='PredicciÃ³n')
plt.fill_between(forecast_global['Year'], forecast_global['yhat_lower'], forecast_global['yhat_upper'], alpha=0.3)
plt.title("Consumo Global Total hasta 2035")
plt.xlabel("AÃ±o")
plt.ylabel("Tazas de cafÃ©")
plt.grid(True)
st.pyplot(fig1)
descripcion_tendencia(forecast_global)

# Por tipo de cafÃ©
st.header("ğŸŒ¿ Consumo Total por Tipo de CafÃ©")
tipo_selected = st.selectbox("Selecciona tipo de cafÃ©:", sorted(df_long['Coffee type'].unique()))
df_tipo = df_long[df_long['Coffee type'] == tipo_selected]
consumo_tipo = df_tipo.groupby('Year')['Consumption'].sum().reset_index()
model_tipo, forecast_tipo = entrenar_modelo(consumo_tipo, 'Year', 'Consumption', horizonte=2035 - consumo_tipo['Year'].max())

fig2 = plt.figure(figsize=(10,4))
plt.plot(forecast_tipo['Year'], forecast_tipo['yhat'], label='PredicciÃ³n', color='green')
plt.fill_between(forecast_tipo['Year'], forecast_tipo['yhat_lower'], forecast_tipo['yhat_upper'], alpha=0.3, color='lightgreen')
plt.title(f"Consumo de {tipo_selected} hasta 2035")
plt.xlabel("AÃ±o")
plt.ylabel("Tazas de cafÃ©")
plt.grid(True)
st.pyplot(fig2)
descripcion_tendencia(forecast_tipo)

# Top 5 paÃ­ses
st.header("ğŸ† Consumo Anual de CafÃ© en los 5 PaÃ­ses con Mayor Consumo")
top5 = df_long.groupby('Country')['Consumption'].sum().nlargest(5).index.tolist()
df_top5 = df_long[df_long['Country'].isin(top5)]
consumo_top5 = df_top5.groupby(['Year', 'Country'])['Consumption'].sum().reset_index()
top_forecast_df = pd.DataFrame()
for pais in top5:
    pais_data = consumo_top5[consumo_top5['Country'] == pais]
    model, forecast = entrenar_modelo(pais_data, 'Year', 'Consumption', horizonte=2035 - pais_data['Year'].max())
    forecast['Country'] = pais
    forecast['Coffee type'] = 'Total'
    top_forecast_df = pd.concat([top_forecast_df, forecast])

fig3, ax = plt.subplots(figsize=(10,5))
for pais in top5:
    data = top_forecast_df[top_forecast_df['Country'] == pais]
    ax.plot(data['Year'], data['yhat'], label=pais)
ax.set_title("Consumo Proyectado hasta 2035 - Top 5 PaÃ­ses")
ax.set_xlabel("AÃ±o")
ax.set_ylabel("Tazas de cafÃ©")
ax.grid(True)
ax.legend()
st.pyplot(fig3)
st.markdown("**ğŸ“Œ Se proyecta que estos paÃ­ses mantendrÃ¡n el liderazgo en consumo hasta 2035.**")

# Interactivo por paÃ­s y tipo
st.header("ğŸ”® PredicciÃ³n Interactiva por PaÃ­s y Tipo (2021â€“2030)")
paises = sorted(df_long['Country'].unique())
pais = st.selectbox("ğŸŒ PaÃ­s", paises)
tipos_disponibles = sorted(df_long[df_long['Country'] == pais]['Coffee type'].unique())
tipo = st.selectbox("â˜• Tipo de cafÃ©", tipos_disponibles)

if st.button("ğŸ”® Predecir consumo"):
    df_filtered = df_long[
        (df_long['Country'] == pais) &
        (df_long['Coffee type'] == tipo)
    ]
    if df_filtered.shape[0] < 2:
        st.warning(f"âŒ No hay suficientes datos para {pais} - {tipo}")
    else:
        model = Prophet()
        df_model = df_filtered.rename(columns={'Consumption': 'y'})
        df_model['ds'] = pd.to_datetime(df_model['Year'], format='%Y')
        df_model = df_model[['ds', 'y']]
        model.fit(df_model)

        ult_ano = df_model['ds'].dt.year.max()
        future = model.make_future_dataframe(periods=2030 - ult_ano, freq='Y')
        forecast = model.predict(future)
        forecast['Year'] = forecast['ds'].dt.year

        fig = model.plot(forecast)
        plt.title(f"PredicciÃ³n de consumo en {pais} - {tipo} hasta 2030")
        plt.grid(True)
        plt.tight_layout()
        st.pyplot(fig)
        descripcion_tendencia(forecast)

        tabla = forecast[['Year', 'yhat', 'yhat_lower', 'yhat_upper']]
        tabla = tabla[tabla['Year'] > ult_ano].round(2)
        tabla_mostrada = tabla.rename(columns={
            'Year': 'AÃ±o',
            'yhat': 'PredicciÃ³n',
            'yhat_lower': 'LÃ­mite inferior',
            'yhat_upper': 'LÃ­mite superior'
        })
        st.subheader("ğŸ“Š Tabla de predicciÃ³n (2021â€“2030)")
        st.dataframe(tabla_mostrada.set_index('AÃ±o'))

        # Descargar como Excel/ CSV
        towrite = io.StringIO()
        tabla_mostrada.to_csv(towrite, index=False)
        b64 = base64.b64encode(towrite.getvalue().encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="prediccion_cafe.csv">ğŸ“¥ Descargar predicciÃ³n en CSV</a>'
        st.markdown(href, unsafe_allow_html=True)

# CHATBOT
st.subheader("ğŸ’¬ Asistente conversacional sobre cafÃ©")
st.markdown("Selecciona una pregunta sugerida o escribe la tuya:")

# Lista de preguntas sugeridas
sugerencias = [
    "Â¿QuÃ© paÃ­s consume menos cafÃ©?",
    "Â¿CuÃ¡l es el tipo de cafÃ© mÃ¡s consumido en Colombia?",
    "Â¿CuÃ¡ntas tazas se consumieron en el aÃ±o 2010?",
    "Â¿QuÃ© tipo de cafÃ© crecerÃ¡ mÃ¡s hasta 2035?",
    "Â¿El consumo global estÃ¡ aumentando o disminuyendo?",
    "Â¿En quÃ© aÃ±o se espera el mayor consumo?",
    "Â¿CuÃ¡l es el paÃ­s con mayor proyecciÃ³n en 2030?"
]

# Mostrar como botones
cols = st.columns(2)
for i, pregunta in enumerate(sugerencias):
    if cols[i % 2].button(f"ğŸ’¬ {pregunta}"):
        st.session_state["chat_sugerencia"] = pregunta


mensaje = st.chat_input("Haz una pregunta sobre los datos o predicciones...")

# Usar sugerencia si fue seleccionada
if "chat_sugerencia" in st.session_state:
    mensaje = st.session_state.pop("chat_sugerencia")

if mensaje:
    with st.spinner("Analizando..."):
        respuesta = responder_chat(mensaje, df_pred=forecast_global, df_real=df_long)
    st.chat_message("user").write(mensaje)
    st.chat_message("assistant").write(respuesta)
